<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"/>
    <title>AgriVision AI • Live Weed & Crop Detection</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Inter', sans-serif; background: #000; color: #fff; overflow: hidden; height: 100vh; }
        .container { position: relative; width: 100%; height: 100%; background: #000; }

        video { width: 100%; height: 100%; object-fit: cover; }

        canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; }

        /* Loading Screen */
        #loading-screen {
            position: fixed; top: 0; left: 0; right: 0; bottom: 0;
            background: #000; z-index: 9999;
            display: flex; flex-direction: column; align-items: center; justify-content: center;
            transition: opacity 0.6s ease;
        }
        #loading-screen.hidden { opacity: 0; pointer-events: none; }
        .spinner {
            width: 60px; height: 60px; border: 6px solid #333;
            border-top: 6px solid #00ff88; border-radius: 50%;
            animation: spin 1s linear infinite; margin-bottom: 20px;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        .status-bar {
            position: absolute; top: 20px; left: 50%; transform: translateX(-50%);
            background: rgba(0,0,0,0.7); backdrop-filter: blur(16px);
            padding: 12px 24px; border-radius: 30px; z-index: 100;
            border: 1px solid rgba(255,255,255,0.1); box-shadow: 0 8px 32px rgba(0,0,0,0.5);
            font-weight: 600; font-size: 14px;
        }
        .dot { width: 10px; height: 10px; border-radius: 50%; background: #00ff88; display: inline-block; margin-right: 10px; box-shadow: 0 0 20px #00ff88; }

        .bottom-panel {
            position: absolute; bottom: 0; left: 0; right: 0; z-index: 50;
            background: rgba(10,10,15,0.95); backdrop-filter: blur(20px);
            border-top: 1px solid rgba(255,255,255,0.1);
            border-radius: 24px 24px 0 0;
            padding: 20px; transition: transform 0.4s cubic-bezier(0.32,1,0.32,1);
            transform: translateY(0);
        }
        .drag-handle {
            width: 50px; height: 5px; background: rgba(255,255,255,0.3); border-radius: 3px;
            margin: 0 auto 16px; cursor: grab;
        }

        .confidence {
            margin: 0 auto 20px;
            text-align: center;
            max-width: 400px;
        }
        .confidence-bar {
            height: 10px; background: rgba(255,255,255,0.1); border-radius: 5px; overflow: hidden;
        }
        .fill { height: 100%; background: linear-gradient(90deg, #00ff88, #00cc66); transition: width 0.5s ease; }
        .conf-label { margin-top: 8px; font-size: 14px; opacity: 0.9; }

        .controls {
            display: flex; justify-content: center; gap: 16px;
        }
        button {
            padding: 14px 28px; font-size: 1.1rem; border: none;
            border-radius: 30px; cursor: pointer; transition: all 0.3s;
        }
        #reset-btn { background: #ff4444; color: white; }
        #reset-btn:hover { background: #ff3333; }
    </style>
</head>
<body>
    <!-- Loading Screen -->
    <div id="loading-screen">
        <div class="spinner"></div>
        <h2>Loading YOLOv11 Model...</h2>
        <p style="margin-top:12px; opacity:0.8;">This may take 10–60 seconds depending on your device and connection.<br>Please wait...</p>
    </div>

    <div class="container">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="canvas"></canvas>

        <div class="status-bar">
            <span class="dot"></span>
            <span id="status-text">Model loaded – point camera at plants</span>
        </div>

        <div class="bottom-panel" id="bottom-panel">
            <div class="drag-handle"></div>

            <div class="confidence">
                <div class="confidence-bar">
                    <div class="fill" id="conf-fill" style="width:0%"></div>
                </div>
                <div class="conf-label">Avg Confidence: <span id="conf-text">0%</span></div>
            </div>

            <div class="controls">
                <button id="reset-btn">Reset Counts</button>
            </div>
        </div>
    </div>

    <script>
        // ───────────────────────────────────────────────
        // ADJUST THESE VALUES HERE
        const MIN_CONFIDENCE = 0.8;   // 0.55–0.70 recommended
        const IOU_THRESHOLD  = 0.6;   // 0.45–0.60 for stricter tracking
        const TRACKER_MAX_AGE = 8;    // 8–15 frames
        // ───────────────────────────────────────────────

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusText = document.getElementById('status-text');
        const loadingScreen = document.getElementById('loading-screen');
        const confFill = document.getElementById('conf-fill');
        const confText = document.getElementById('conf-text');
        const resetBtn = document.getElementById('reset-btn');

        let model;
        let isRunning = true;
        let frameCount = 0;

        // Tracking
        let nextId = 1;
        const trackers = new Map(); // id → {bbox, classId, label, age, visibleCount}

        async function loadModel() {
            try {
                statusText.textContent = "Loading model... Please wait";
                model = await tf.loadGraphModel('best_web_model/model.json');
                console.log("Model loaded successfully");

                // Hide loading screen after successful load
                loadingScreen.classList.add('hidden');
                statusText.textContent = "Model loaded! Point camera at plants";

                startDetection();
            } catch (e) {
                loadingScreen.querySelector('h2').textContent = "Model Load Failed";
                loadingScreen.querySelector('p').textContent = "Try refreshing or use a stronger device/connection.";
                console.error("Model load error:", e);
            }
        }

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'environment', width: { ideal: 1280 }, height: { ideal: 720 } }
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    console.log("Camera started:", video.videoWidth, "×", video.videoHeight);
                };
            } catch (e) {
                console.error("Camera error:", e);
                statusText.textContent = "Camera access denied";
            }
        }

        function iou(box1, box2) {
            const [x1, y1, x2, y2] = box1;
            const [xA, yA, xB, yB] = box2;
            const xi1 = Math.max(x1, xA);
            const yi1 = Math.max(y1, yA);
            const xi2 = Math.min(x2, xB);
            const yi2 = Math.min(y2, yB);
            const interArea = Math.max(0, xi2 - xi1) * Math.max(0, yi2 - yi1);
            const box1Area = (x2 - x1) * (y2 - y1);
            const box2Area = (xB - xA) * (yB - yA);
            return interArea / (box1Area + box2Area - interArea);
        }

        async function startDetection() {
            if (!isRunning) return;

            frameCount++;
            tf.engine().startScope();

            const img = tf.browser.fromPixels(video);
            const resized = tf.image.resizeBilinear(img, [640, 640]);
            const normalized = resized.div(255.0);
            const input = normalized.expandDims(0);

            let prediction;
            try {
                prediction = await model.executeAsync(input);
            } catch (e) {
                console.error("Inference error:", e);
                tf.engine().endScope();
                requestAnimationFrame(startDetection);
                return;
            }

            let output = Array.isArray(prediction) ? prediction[0] : prediction;

            if (output.shape[1] === 6 && output.shape[2] === 8400) {
                output = output.transpose([0, 2, 1]);
            }

            const data = await output.array();
            const boxes = data[0];

            console.log(`Frame ${frameCount} - Raw boxes: ${boxes.length}`);

            const currentDetections = [];
            for (let i = 0; i < boxes.length; i++) {
                const [cx, cy, w, h, conf1, conf2] = boxes[i];
                const conf = Math.max(conf1, conf2);
                if (conf < MIN_CONFIDENCE) continue;

                const classId = conf1 > conf2 ? 0 : 1;
                const x = (cx - w / 2) * 640;
                const y = (cy - h / 2) * 640;
                const width = w * 640;
                const height = h * 640;

                currentDetections.push({
                    bbox: [x, y, x + width, y + height],
                    confidence: conf,
                    classId
                });
            }

            console.log(`After conf filter (${MIN_CONFIDENCE}): ${currentDetections.length} candidates`);

            // ─── SORT-like tracking ───────────────────────────────────────
            const matched = new Set();
            const newTrackers = new Map();

            currentDetections.forEach(det => {
                let bestMatch = null;
                let bestIou = 0;

                trackers.forEach((tracker, id) => {
                    const i = iou(det.bbox, tracker.bbox);
                    if (i > bestIou && i > IOU_THRESHOLD) {
                        bestIou = i;
                        bestMatch = id;
                    }
                });

                if (bestMatch !== null) {
                    matched.add(bestMatch);
                    const t = trackers.get(bestMatch);
                    t.bbox = det.bbox;
                    t.confidence = det.confidence;
                    t.age = 0;
                    t.visibleCount++;
                    newTrackers.set(bestMatch, t);
                } else {
                    const id = nextId++;
                    const label = det.classId === 0 ? `WEED #${id}` : `CROP #${id}`;
                    newTrackers.set(id, {
                        bbox: det.bbox,
                        classId: det.classId,
                        label,
                        confidence: det.confidence,
                        age: 0,
                        visibleCount: 1
                    });
                }
            });

            trackers.forEach((t, id) => {
                if (!matched.has(id)) {
                    t.age++;
                    if (t.age <= TRACKER_MAX_AGE) newTrackers.set(id, t);
                }
            });

            trackers.clear();
            newTrackers.forEach((t, id) => trackers.set(id, t));

            console.log(`Final active trackers: ${trackers.size}`);

            // ─── Draw ─────────────────────────────────────────────────────
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            let visibleCrops = 0;
            let sumConf = 0;
            let visibleCount = 0;

            trackers.forEach(t => {
                if (t.age > 2 || t.confidence < MIN_CONFIDENCE) return;

                const [x1, y1, x2, y2] = t.bbox;
                const scaleX = canvas.width / 640;
                const scaleY = canvas.height / 640;

                const sx1 = x1 * scaleX;
                const sy1 = y1 * scaleY;
                const sx2 = x2 * scaleX;
                const sy2 = y2 * scaleY;

                const isWeed = t.classId === 0;
                const color = isWeed ? '#ff4444' : '#44ff44';

                ctx.strokeStyle = color;
                ctx.lineWidth = 4;
                ctx.strokeRect(sx1, sy1, sx2 - sx1, sy2 - sy1);

                const label = `${t.label} ${(t.confidence * 100).toFixed(0)}%`;
                const textWidth = ctx.measureText(label).width;

                ctx.fillStyle = color;
                ctx.fillRect(sx1, sy1 - 34, textWidth + 20, 34);

                ctx.fillStyle = 'white';
                ctx.font = 'bold 16px Inter';
                ctx.fillText(label, sx1 + 10, sy1 - 10);

                if (!isWeed) visibleCrops++;
                sumConf += t.confidence;
                visibleCount++;
            });

            // ─── Update UI (only confidence) ──────────────────────────────
            const avg = visibleCount > 0 ? sumConf / visibleCount : 0;
            confFill.style.width = `${avg * 100}%`;
            confText.textContent = `${(avg * 100).toFixed(1)}%`;

            tf.engine().endScope();
            requestAnimationFrame(startDetection);
        }

        // Reset
        resetBtn.onclick = () => {
            nextId = 1;
            trackers.clear();
            statusText.textContent = "Counts & trackers reset";
        };

        // Start everything
        startCamera();
        loadModel();
    </script>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"/>
    <title>AgriVision AI ‚Ä¢ Professional Weed & Crop Detection</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Inter', system-ui, sans-serif; background: #0a0a0a; color: #e0e0e0; min-height: 100vh; overflow: hidden; }
        .container { height: 100vh; display: flex; flex-direction: column; position: relative; background: linear-gradient(135deg, #0f0f0f 0%, #000 100%); }
        .status-bar { position: absolute; top: 16px; left: 16px; right: 16px; z-index: 100; background: rgba(20,20,20,0.6); backdrop-filter: blur(12px); border-radius: 16px; padding: 12px 16px; border: 1px solid rgba(255,255,255,0.08); display: flex; align-items: center; gap: 12px; box-shadow: 0 8px 32px rgba(0,0,0,0.4); }
        .status-dot { width: 10px; height: 10px; border-radius: 50%; background: #00ff9d; box-shadow: 0 0 12px #00ff9d88; }
        .status-text { flex: 1; }
        .status-title { font-size: 14px; font-weight: 600; color: #00ff9d; }
        .status-desc { font-size: 12px; opacity: 0.7; margin-top: 2px; }
        .frame-count { background: rgba(255,255,255,0.08); padding: 6px 12px; border-radius: 8px; font-size: 12px; font-weight: 500; }
        .detection-area { flex: 1; position: relative; overflow: hidden; }
        #video { width: 100%; height: 100%; object-fit: contain; background: #000; }
        canvas { position: absolute; inset: 0; pointer-events: none; }
        .bottom-panel-wrapper { position: absolute; bottom: 0; left: 0; right: 0; z-index: 50; transition: transform 0.4s cubic-bezier(0.22, 1, 0.36, 1); }
        .bottom-panel { background: rgba(15,15,15,0.92); backdrop-filter: blur(20px); border-top-left-radius: 24px; border-top-right-radius: 24px; border-top: 1px solid rgba(255,255,255,0.08); box-shadow: 0 -8px 40px rgba(0,0,0,0.6); padding: 0 20px 20px; touch-action: pan-y; }
        .drag-handle { width: 40px; height: 4px; background: rgba(255,255,255,0.3); border-radius: 2px; margin: 12px auto; cursor: grab; }
        .stats-grid { display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; margin: 20px 0; }
        .stat-card { background: rgba(255,255,255,0.05); border-radius: 16px; padding: 16px; text-align: center; border: 1px solid rgba(255,255,255,0.08); transition: all 0.3s ease; }
        .stat-card:hover { transform: translateY(-4px); background: rgba(255,255,255,0.08); }
        .stat-icon { font-size: 28px; margin-bottom: 8px; }
        .stat-value { font-size: 28px; font-weight: 700; margin: 4px 0; }
        .stat-label { font-size: 13px; opacity: 0.7; }
        .confidence-bar { height: 8px; background: rgba(255,255,255,0.1); border-radius: 4px; overflow: hidden; margin: 12px 0; }
        .confidence-fill { height: 100%; background: linear-gradient(90deg, #00ff9d, #4CAF50); transition: width 0.6s ease; }
        .bottom-actions { display: flex; justify-content: space-around; margin-top: 16px; }
        .action-btn { background: rgba(255,255,255,0.08); border: 1px solid rgba(255,255,255,0.15); color: white; padding: 12px 24px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.3s; }
        .action-btn:hover { background: rgba(255,255,255,0.15); transform: translateY(-2px); }
        .primary-btn { background: #4CAF50; border-color: #4CAF50; }
        .primary-btn:hover { background: #43A047; }
        @media (max-width: 600px) { .stats-grid { gap: 12px; } .stat-value { font-size: 22px; } .action-btn { padding: 10px 16px; font-size: 14px; } }
    </style>
</head>
<body>
    <div class="container">
        <div class="status-bar">
            <div class="status-dot"></div>
            <div class="status-text">
                <p class="status-title" id="detection-title">Live Detection Active</p>
                <p class="status-desc" id="status-desc">Loading model...</p>
            </div>
            <div class="frame-count">Frame: <span id="frame-count">0</span></div>
        </div>

        <div class="detection-area">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="canvas"></canvas>
        </div>

        <div class="bottom-panel-wrapper" id="bottom-wrapper">
            <div class="bottom-panel">
                <div class="drag-handle" id="drag-handle"></div>

                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-icon">üåø</div>
                        <div class="stat-value" id="crop-count">0</div>
                        <div class="stat-label">Crops</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-icon">‚ö†Ô∏è</div>
                        <div class="stat-value" id="weed-count">0</div>
                        <div class="stat-label">Weeds</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-icon">üìä</div>
                        <div class="stat-value" id="total-count">0</div>
                        <div class="stat-label">Total</div>
                    </div>
                </div>

                <div class="confidence-bar">
                    <div class="confidence-fill" id="confidence-fill"></div>
                </div>
                <div class="progress-label" id="confidence-label">Avg Confidence: 0%</div>

                <div class="bottom-actions">
                    <button class="action-btn" id="pause-btn">Pause Detection</button>
                    <button class="action-btn primary-btn" id="reset-btn">Reset Counts</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusDesc = document.getElementById('status-desc');
        const frameCount = document.getElementById('frame-count');
        const cropCount = document.getElementById('crop-count');
        const weedCount = document.getElementById('weed-count');
        const totalCount = document.getElementById('total-count');
        const confidenceFill = document.getElementById('confidence-fill');
        const confidenceLabel = document.getElementById('confidence-label');
        const pauseBtn = document.getElementById('pause-btn');
        const resetBtn = document.getElementById('reset-btn');
        const bottomWrapper = document.getElementById('bottom-wrapper');
        const dragHandle = document.getElementById('drag-handle');

        let model;
        let isDetecting = true;
        let frameNum = 0;
        let totalWeeds = 0;
        let totalCrops = 0;
        let avgConf = 0;
        let lastY = 0;
        let dragging = false;
        let animationId = null;

        // Tracking IDs
        let weedId = 0;
        let cropId = 0;
        const seenObjects = new Set();
        const objectLabels = new Map();

        // CAMERA SETTINGS FROM OLD CODE (high quality)
        const constraints = {
            video: {
                facingMode: { ideal: 'environment' },
                width: { min: 1280, ideal: 1920 },
                height: { min: 720, ideal: 1080 },
            }
        };

        // THRESHOLDS
        const CONFIDENCE_THRESHOLD = 0.8; // Increased to 0.7
        const IOU_THRESHOLD = 0.7; // Increased to 0.6

        function resizeCanvas() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
        }

        // CAMERA START FROM OLD CODE
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    resizeCanvas();
                    statusDesc.textContent = 'Camera ready';
                    loadModel();
                };
                video.onresize = resizeCanvas;
            } catch (e) {
                console.error(e);
                statusDesc.textContent = 'Camera failed - using fallback';
                // Try basic constraints
                try {
                    const fallback = { video: true };
                    const stream = await navigator.mediaDevices.getUserMedia(fallback);
                    video.srcObject = stream;
                    video.play();
                    loadModel();
                } catch (fallbackError) {
                    statusDesc.textContent = 'Cannot access camera';
                    console.error('Fallback also failed:', fallbackError);
                }
            }
        }

        // MODEL LOADING FROM NEW CODE (with multiple paths)
        async function loadModel() {
            try {
                // Try different model paths
                const modelPaths = [
                    'best_model_web/model.json',
                    'model.json',
                    './model.json',
                    'best/model.json'
                ];
                
                let modelLoaded = false;
                for (const path of modelPaths) {
                    try {
                        console.log(`Trying to load model from: ${path}`);
                        model = await tf.loadGraphModel(path);
                        console.log('‚úÖ Model loaded successfully from:', path);
                        modelLoaded = true;
                        break;
                    } catch (e) {
                        console.log(`Failed to load from ${path}:`, e.message);
                    }
                }
                
                if (!modelLoaded) {
                    throw new Error('Could not load model from any path');
                }
                
                statusDesc.textContent = 'High-precision model loaded ‚Äì detecting with 70%+ confidence';
                detectFrame();
            } catch (e) {
                console.error('Model load error:', e);
                statusDesc.textContent = 'Model load failed ‚Äì check console';
            }
        }

        // FIXED NMS FUNCTION FROM NEW CODE (no const reassignment bug)
        function nonMaxSuppression(boxes, scores, iouThreshold = IOU_THRESHOLD) {
            const indices = [];
            let remaining = scores.map((s, i) => ({score: s, index: i}))
                                  .sort((a, b) => b.score - a.score);

            while (remaining.length > 0) {
                const best = remaining.shift();
                indices.push(best.index);

                remaining = remaining.filter(item => {
                    const iou = calculateIOU(boxes[best.index], boxes[item.index]);
                    return iou <= iouThreshold;
                });
            }
            return indices;
        }

        function calculateIOU(box1, box2) {
            const [x1, y1, w1, h1] = box1;
            const [x2, y2, w2, h2] = box2;

            const xi1 = Math.max(x1, x2);
            const yi1 = Math.max(y1, y2);
            const xi2 = Math.min(x1 + w1, x2 + w2);
            const yi2 = Math.min(y1 + h1, y2 + h2);

            const interArea = Math.max(0, xi2 - xi1) * Math.max(0, yi2 - yi1);
            const box1Area = w1 * h1;
            const box2Area = w2 * h2;
            const unionArea = box1Area + box2Area - interArea;
            
            return unionArea > 0 ? interArea / unionArea : 0;
        }

        // DETECTION LOGIC FROM NEW CODE (with proper tensor cleanup)
        async function detectFrame() {
            if (!isDetecting || !model || !video.videoWidth) {
                animationId = requestAnimationFrame(detectFrame);
                return;
            }

            frameNum++;
            frameCount.textContent = frameNum;

            tf.engine().startScope();

            try {
                const img = tf.browser.fromPixels(video);
                const resized = tf.image.resizeBilinear(img, [640, 640]);
                const normalized = resized.div(255.0);
                const batched = normalized.expandDims(0);

                // Use model.execute() instead of executeAsync() when possible
                let prediction;
                try {
                    prediction = await model.executeAsync(batched);
                } catch (asyncError) {
                    console.log('Async execution failed, trying sync:', asyncError.message);
                    prediction = model.execute(batched);
                }

                // Handle prediction output
                let output = Array.isArray(prediction) ? prediction[0] : prediction;
                
                // Log for debugging
                console.log('Output shape:', output.shape);

                // Process based on shape
                const shape = output.shape;
                const data = await output.data();
                
                const rawDetections = [];
                
                if (shape[1] === 6 && shape[2] === 8400) {
                    // Shape: [1, 6, 8400] - standard YOLO format
                    for (let i = 0; i < 8400; i++) {
                        const cx = data[i];
                        const cy = data[8400 + i];
                        const w = data[16800 + i];
                        const h = data[25200 + i];
                        const weedConf = data[33600 + i];
                        const cropConf = data[42000 + i];

                        const conf = Math.max(weedConf, cropConf);
                        if (conf < CONFIDENCE_THRESHOLD) continue; // Use higher threshold

                        const classId = weedConf > cropConf ? 0 : 1;
                        const x = (cx - w / 2) * 640;
                        const y = (cy - h / 2) * 640;
                        const width = w * 640;
                        const height = h * 640;

                        if (width > 0 && height > 0) {
                            rawDetections.push({
                                bbox: [x, y, width, height],
                                confidence: conf,
                                classId
                            });
                        }
                    }
                } else if (shape[1] === 8400 && shape[2] === 6) {
                    // Shape: [1, 8400, 6] - transposed format
                    for (let i = 0; i < 8400; i++) {
                        const offset = i * 6;
                        const cx = data[offset];
                        const cy = data[offset + 1];
                        const w = data[offset + 2];
                        const h = data[offset + 3];
                        const weedConf = data[offset + 4];
                        const cropConf = data[offset + 5];

                        const conf = Math.max(weedConf, cropConf);
                        if (conf < CONFIDENCE_THRESHOLD) continue; // Use higher threshold

                        const classId = weedConf > cropConf ? 0 : 1;
                        const x = (cx - w / 2) * 640;
                        const y = (cy - h / 2) * 640;
                        const width = w * 640;
                        const height = h * 640;

                        if (width > 0 && height > 0) {
                            rawDetections.push({
                                bbox: [x, y, width, height],
                                confidence: conf,
                                classId
                            });
                        }
                    }
                }

                // Clean up tensors
                img.dispose();
                resized.dispose();
                normalized.dispose();
                batched.dispose();
                output.dispose();
                if (prediction && prediction.dispose) prediction.dispose();

                // Apply NMS if we have detections
                if (rawDetections.length > 0) {
                    const boxes = rawDetections.map(d => d.bbox);
                    const scores = rawDetections.map(d => d.confidence);
                    const indices = nonMaxSuppression(boxes, scores, IOU_THRESHOLD);

                    const detections = indices.map(idx => {
                        const d = rawDetections[idx];
                        const isWeed = d.classId === 0;
                        const objectId = `${d.classId}_${Math.round(d.bbox[0])}_${Math.round(d.bbox[1])}`;

                        let label;
                        if (!seenObjects.has(objectId)) {
                            seenObjects.add(objectId);
                            if (isWeed) {
                                weedId++;
                                totalWeeds++;
                                label = `WEED #${weedId}`;
                            } else {
                                cropId++;
                                totalCrops++;
                                label = `CROP #${cropId}`;
                            }
                            objectLabels.set(objectId, label);
                        } else {
                            label = objectLabels.get(objectId);
                        }

                        return {
                            label,
                            confidence: d.confidence,
                            bbox: d.bbox,
                            class: isWeed ? 'weed' : 'crop'
                        };
                    });

                    // Update stats
                    totalCount.textContent = totalWeeds + totalCrops;
                    weedCount.textContent = totalWeeds;
                    cropCount.textContent = totalCrops;

                    if (detections.length > 0) {
                        avgConf = detections.reduce((s, d) => s + d.confidence, 0) / detections.length;
                        const confidencePercent = Math.min(100, avgConf * 100);
                        confidenceFill.style.width = `${confidencePercent}%`;
                        confidenceLabel.textContent = `Avg Confidence: ${confidencePercent.toFixed(1)}%`;
                        statusDesc.textContent = `Detected ${detections.length} objects (70%+ confidence)`;
                    } else {
                        statusDesc.textContent = 'No high-confidence detections ‚Äì move closer/improve lighting';
                    }

                    // Draw detections
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    
                    detections.forEach(d => {
                        const scaleX = canvas.width / 640;
                        const scaleY = canvas.height / 640;

                        const sx = d.bbox[0] * scaleX;
                        const sy = d.bbox[1] * scaleY;
                        const sw = d.bbox[2] * scaleX;
                        const sh = d.bbox[3] * scaleY;

                        // Draw bounding box
                        ctx.lineWidth = 3;
                        ctx.strokeStyle = d.class === 'weed' ? '#ff4444' : '#44aa44';
                        ctx.strokeRect(sx, sy, sw, sh);

                        // Draw label background
                        const labelText = `${d.label} ${(d.confidence * 100).toFixed(0)}%`;
                        ctx.font = 'bold 14px Inter';
                        const textWidth = ctx.measureText(labelText).width;
                        const labelWidth = textWidth + 20;
                        
                        ctx.fillStyle = d.class === 'weed' ? '#ff4444' : '#44aa44';
                        ctx.fillRect(sx, sy - 30, labelWidth, 30);

                        // Draw label text
                        ctx.fillStyle = 'white';
                        ctx.font = 'bold 14px Inter';
                        ctx.fillText(labelText, sx + 10, sy - 10);
                    });
                } else {
                    statusDesc.textContent = 'No high-confidence detections ‚Äì move closer/good light';
                }

            } catch (e) {
                console.error('Detection error:', e);
                statusDesc.textContent = 'Detection error - continuing';
            }

            tf.engine().endScope();
            animationId = requestAnimationFrame(detectFrame);
        }

        // Button event listeners from new code
        pauseBtn.addEventListener('click', () => {
            isDetecting = !isDetecting;
            pauseBtn.textContent = isDetecting ? 'Pause Detection' : 'Resume Detection';
            statusDesc.textContent = isDetecting ? 'Detection resumed' : 'Detection paused';
            
            if (isDetecting && !animationId) {
                detectFrame();
            }
        });

        resetBtn.addEventListener('click', () => {
            totalWeeds = 0;
            totalCrops = 0;
            weedId = 0;
            cropId = 0;
            seenObjects.clear();
            objectLabels.clear();
            
            weedCount.textContent = '0';
            cropCount.textContent = '0';
            totalCount.textContent = '0';
            confidenceFill.style.width = '0%';
            confidenceLabel.textContent = 'Avg Confidence: 0%';
            statusDesc.textContent = 'Counts reset';
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
        });

        // Draggable panel functionality
        let startY = 0;
        let startHeight = 0;
        const minHeight = 100;
        const maxHeight = 400;

        dragHandle.addEventListener('mousedown', startDrag);
        dragHandle.addEventListener('touchstart', startDrag);

        function startDrag(e) {
            dragging = true;
            startY = e.type === 'mousedown' ? e.clientY : e.touches[0].clientY;
            startHeight = bottomWrapper.offsetHeight;
            
            document.addEventListener('mousemove', doDrag);
            document.addEventListener('touchmove', doDrag);
            document.addEventListener('mouseup', stopDrag);
            document.addEventListener('touchend', stopDrag);
            
            e.preventDefault();
        }

        function doDrag(e) {
            if (!dragging) return;
            
            const currentY = e.type === 'mousedown' ? e.clientY : e.touches[0].clientY;
            const deltaY = startY - currentY;
            let newHeight = startHeight + deltaY;
            
            // Constrain height
            newHeight = Math.max(minHeight, Math.min(maxHeight, newHeight));
            
            bottomWrapper.style.height = `${newHeight}px`;
            e.preventDefault();
        }

        function stopDrag() {
            dragging = false;
            document.removeEventListener('mousemove', doDrag);
            document.removeEventListener('touchmove', doDrag);
            document.removeEventListener('mouseup', stopDrag);
            document.removeEventListener('touchend', stopDrag);
        }

        // Start the application
        startCamera();
    </script>
</body>
</html>

